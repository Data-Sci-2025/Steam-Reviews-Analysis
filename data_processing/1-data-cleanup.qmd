---
title: "analysis pipeline"
format: gfm
---

```{r}
#| label: setup
#| include: false
library(tidyverse)
library(tidytext)
```

**Note**: reviews.csv is too large to upload to github, but using the data which is uploaded and the "data exploration" file, if you execute the write_csv chunk, you should be able to recreate it just fine. You may have to adjust the file path to read in for this one. 


```{r}
#| label: readingin
reviews_df <- read_csv("../private/reviews.csv")
reviews_df
```

```{r}
#| label: game-ids
reviews_df |>
  distinct(steam_id)
```


## Cleaning Up


```{r}
#| label: posneg
reviews_df <- reviews_df |>
    mutate(review_type =  str_replace_all(review_type, 
                c("‚úÖ" = "POS",
                  "‚ùå" = "NEG")))
```


Fix those pesky emoji columns (I'm going to ditch the "purchased" column later on, so I didn't bother)

```{r}
#| label: reviews-df
reviews_df
```


```{r}
#| label: colchecks
diffrows <- reviews_df[reviews_df$review != reviews_df$engtxt, ]
diffrows
```

The engtxt column is not actually different from the review column, (it seems to auto translate review text in other languages to varying degrees of success, but I don't want to study translations). The only difference among English reviews being conversions of any reviews that just say "xx%" (100% being converted to 1) or anything with x/10 being also converted to a string of numbers. Since it's essentially the same data, I'll ditch the engtxt column and keep the review one.

Now for column decisions. I'll keep review_id since it's a unique value for each different review. 

I don't know that the date column is extremely important. I might want to look at how quickly games get reviews (are they concentrated at release and fall off, or is it relatively steady? any spikes?) but I will probably edit the column to a better format. Ditch the time, look into whatever format works best in R. 

I don't think the purchased col is extremely important, it only marks if a review writer has purchased the game or not, which is not key to any of my analysis.

score and upvotes are based on user response to a comment. Users can upvote for helpfulness of a review, or mark it as funny. I can't find data on how exactly the review score is calculated, but I don't think these two factors will play a huge role in what I'm looking to do. 


```{r}
#| label: reviews-df2
#narrowing the df down to only the columns I want
reviews_df <- reviews_df |>
  select(review_id:review_type, review, steam_id)
reviews_df
```

Now, I wanted to verify everything is correct. If every review ID is unique and I didn't accidentally duplicate anything, then piping the review_id column into distinct() should be the exact same dimensions as the full dataframe.

I had to run some fixes, but it's all good now!


```{r}
#| label: rowscheck
reviews_df |>
  distinct(review_id)
```


## List of Goals

- adjust the date column (DONE)
- clean up the text of non text items (DONE)
- Word tokens and word count per review (IN PROGRESS)
- word types
- TTR

**Early Exploration**

- average review length
- most common words (with and without stop words)
- most common words for pos and for neg
- some stats (correlation) - length and review type, review and rating type, maybe some others
- TF-IDF

**Later Goals**

- build a classifier

## Date column

Date format as is: 2025.08.29 02:05

  - remove timestamp
  - reformat
  - change column class

```{r}
#| label: datecol
reviews_df <- reviews_df |>
  mutate(date = str_replace_all(date, "(\\d{4})\\.(\\d{2})\\.(\\d{2}).*", "\\1-\\2-\\3"))
reviews_df$date <- as.Date(reviews_df$date)  
  
reviews_df
```


## Text Cleaning

```{r}
#| label: review-text
reviews_df |>
  select(review)
```


```{r}
#| label: text-replace
reviews_df <- reviews_df |>
   mutate(review =  str_replace_all(review, 
                c("\n" = " ",
                  "\\(" = "",
                  "\\)" = "",
                  "https.*? " = "",
                  "https.*\\b" = "",
                  "http.*? " = "",
                  "http.*\\b" = "",
                  "\\b\\+\\b" = "",
                  " \\+ " = "",
                  "(\\w)/(\\w)" = "\\1 \\2",
                  "(\\w) / (\\w)" = "\\1 \\2",
                  "([a-z]{2,})\\.([a-z]{2,})" = "\\1 \\2",
                  "\\[.*?\\]" = "",
                  " ==+ " = "",
                  "‚†∏|‚¢π|‚†£|‚£õ|‚££|‚£Å|‚£ñ|‚£≠|‚†É|‚¢ª|‚£ß|‚£Ω" = "",
                  "‚£∑|‚£ü|‚¢∂|‚¢£|‚†Ñ|‚°ø|‚£Æ|‚£ª|‚£¶|‚¢õ|‚†ø|‚¢≠|‚†º|‚¢Ä" = "",
                  "‚°â|‚£∂|‚†ò|‚¢ø|‚°†|‚¢Ü|‚£≥|‚°µ|‚°Ö|‚†ô|‚£º|‚°Ñ|‚°ß|‚¢á" = "",
                  "‚£¥|‚£å|‚¢Ω|‚†ª|‚°õ|‚£§|‚°ù|‚£æ|‚†ö|‚£Ä|‚†è|‚°ª|‚¢ò|‚†é" = "",
                  "‚£ù|‚£∏|‚£∞|‚°Ü|‚£±|‚£°|‚¢ü|‚£Ø|‚°ü|‚¢†|‚†ë|‚†õ|‚¢∏|‚¢Ø" = "",
                  "‚¢é|‚£ï|‚°Æ|‚†ù|‚°æ|‚°Ø|‚†ï|‚°π|‚°Ç|‚¢à|‚†ü|‚†¢|‚£é" = "",
                  "‚°™|‚°±|‚¢î|‚°ë|‚¢ä|‚¢ä|‚††|‚†°|‚†à|‚°å|‚†™|‚£∫|‚°Ω" = "",
                  "‚£ó|‚¢â|‚¢Ñ|‚£ê|‚¢Ç|‚¢ê|‚°î|‚°Ä|‚†Å|‚¢ë|‚¢®|‚°Å" = "",
                  "‚¢Æ|‚£Ü|‚†ê|‚£´|‚¢∑|‚¢Æ|‚¢ó|‚¢™|‚£¨|‚¢ú|‚¢æ|‚£û" = "",
                  "‚¢ó|‚†•|‚†®|‚¢™|‚†Ç|‚£¨|‚°ó|‚†ß|‚¢û|‚£™|‚¢±|‚£¨" = "",
                  "‚°®|‚°∑|‚¢ö|‚†π|‚°é|‚¢•|‚†Ä|‚°∫|‚¢å|‚°ä|‚°°|‚†±|‚†å" = "",
                  "‚°≤|‚£π|‚£ë|‚£®|‚¢≥|‚¢°|‚£ú|‚¢µ|‚£î|‚°∏|‚°≠|‚¢É" = "",
                  "‚¢¥|‚¢ï|‚°á|‚¢¨|‚¢Ö|‚£µ|‚†Æ|‚¢è|‚°í|‚°´|‚°ê|‚°≥" = "",
                  "‚†Ø|‚¢¢|‚°©|‚£É|‚†î|‚†ú|‚†á|‚†Ö|‚£á|‚°∞|‚†∞|‚£Ö" = "",
                  "‚°ò|‚°É|‚¢∞|‚°¨|‚°ú|‚¢ù|‚¢©|‚°¢|‚°º|‚£ò|‚†¨|‚†ä|‚¢§" = "",
                  "‚†´|‚¢º|‚°ï|‚£≤|‚°è|‚¢∫|‚°à|‚†§|‚£•|‚°•|‚†∂|‚†Ω|‚£•|‚¢¶" = "",
                  "‚†©|‚°ç|‚†µ|‚£â|‚£ö|‚†¥|‚†≠|‚£ì|‚°ã|‚†ó|‚£Ñ|‚£à|‚†ç" = "",
                  "‚†∫|‚£¢|‚†∑|‚†ã|‚†æ|‚£†|‚°¥|‚†Ü|‚¢ñ|‚†û|‚¢≤|‚¢Å|‚†â|‚¢ã" = "",
                  "‚¢ß|‚£Ç|‚¢ô|‚†≥|‚£è|‚°£|‚°û|‚†í|‚°∂|‚£©|‚†ì|‚£ç|‚†≤|‚°§" = "",
                  "‚¢´|‚£ô|‚£ä|‚†ñ|‚†¶|‚°ô|‚¢ì|‚°¶|‚£í|‚¢í|‚¢ç|‚¢í|‚£ã|‚£ã|‚°ñ|‚£ø|‚°ö|‚°ì" = "",                  "‚ñÑ|‚ñë|‚îå|‚îº|‚ñê|‚ñÄ|‚ñì|‚ïù|‚ïî|‚ñå|‚ïó|‚ïö|‚ïê|‚ïë|‚ñí|√ë|‚îÇ|‚à©|‚ïì|‚ï´" = "",
                  "‚ïô|‚ï°|‚ï†|‚äô|‚ñÖ|‚î§|‚óè|‚ñÇ|‚ñÉ|‚ó•|‚ñà" = "",
                

                  "‚îÄ‚îÄ+" = "‚îÄ",
                  "__+" = "_",
                  
                  "  +" = " ",
                  
                  "^ $" = ""
                  
                  )
                
                
                ))
```


Using str_view and str_replace I'm cleaning up the review text so I can conduct some real analysis. 
  
For the sake of processing text, I'm first removing any parenthesis included. it could be interesting what gets put in a parenthetical statement vs outside, but for pure analysis and vectorizing I don't want them. 

There are some included kind of html(?) tags like [b] and [/b] or [h1] etc. I want to get rid of those too. 

Getting rid of /, sometimes it appears as word/word and others word / word. Replacing it with a space and will later process to move extra spaces down to one space
  - sometimes it appears in 7/10 or something. I'm keeping those but I have to think about what to do with it. It also depends on how the tokenizer handles it. If it tokenizes to [7] [/] [10] I think that's acceptable.
  

### Emojis

Question - what do to with emojis? 

Sometimes they are used stylistically to split up reviews:
üìö Story / Narrative, ‚åõ Length, üîÅ Replayability

Other times functionally (this is about a game's difficulty):
üî≤ Too easy
‚òëÔ∏è Casual-friendly
üî≤ Balanced/Normal
üî≤ Challenging
üî≤ Brutal but fair
üî≤ Pure chaos (PvP focus)

Sometimes in place of words:
At least one review, start to finish, contains one item only - üí©
Another one looks like: This game is üí© but i still love it


There are some other quirks to the reviews:

  - Some reviews also have no words and will just say "7/10" and nothing else, I'm leaving those as-is.

  - There are a lot abbreviations. I've seen af, wtf, omg, lmao, etc etc. I'm leaving those as-is 

  - There are also emoticons in the pre-emoji style: :D, xD etc I even saw ¬∞ Õú ñ Õ°¬∞, Ôæâ‚óï„ÉÆ‚óïÔæâ*:ÔΩ•Ôæü‚úß ... they're not NOT informative, so I'll also leave those (unless I have to revisit later)

  - LOTS of formatting choices people make for visual purposes. =====, ‚òë and ‚òê (not as emojis). For the second I will leave them as they are and treat them almost as an emoji. For formatting, I'll see what I can do about cutting down long lines of equals, hyphens, underscores, etc.

  - Review art(?)
  
![](../notes_and_info/reviewimg.PNG)

There are a number of reviews using ‚£ø (and all the variations in the replace text chunk above) to create a kind of ASCII art that can be safely removed, it is not speech information at all.

  - Finally, links
links? Lots of people are linking to things in their reviews. I don't want those.


In progress notes:
I got rid of a bunch of ======= but there are still some others.... but I can't capture ==+ without also capturing a few reviews that are just "8==D" which I GUESS counts as a valid review, enough so that I don't want to just erase parts of it.


## Tokenizing

Setting up the tokenizing here to see if there's anything I need to change in the text cleanup chunk above before I move onto an analysis qmd

Because of the way unnest_tokens works, it spits out a DF with 11+ million rows, one token per row. My steps are:
  - new df with tokenized reviews
  - merged df with those tokens combined into a list of tokens per unique review ID
  - join the merged df with the original reviews df by mapping onto the review ID


```{r}
#| label: tokens
tokens_df <- reviews_df |>
  unnest_tokens(tokens, review, drop=FALSE, strip_punct=FALSE)

nrow(tokens_df)
```

Manually removing punctuation from the tokenized words in order to preserve emojis in other reviews.


```{r}
#| label: nonwords
rows_not_word <- tokens_df |>
  filter(!grepl("^[A-Za-z]+$", tokens))

rows_not_word
```


```{r}
#| label: stopwords
mystopwords <- tibble(tokens = c(",", "-", ".", "‚Äî", '‚Äú', '‚Äù', ":", "!", "?", "'", '"', ";", "&", ">", "‚Äì", "<", "~", "‚Äô", "¬¥", "‚Ä¢", "‚ó§", "‚ó¢", "‚ñî", "‚îä", "‚ï≠", "‚ïÆ", "‚îÉ", "‚ï≤", "‚ó§‚Äé", "‚îà", "‚ñè", "‚ñï",  "„Éï", "Ôºû", "„ÉüÔºøx", "Ôæâ", "Ôø£", "‰∫å„Å§", "„ÉΩÔºø_„ÉΩ_", "‚Ä¶", "‚ï±", "`", "„Éé", "„ÉΩ", "|", "_", "Ôºº", "{", "}",  "‚îà", "#", "‚óï", "„ÉÆ", "‚óï", "ÔΩ•Ôæü", "ÔºøÔºø", "‚Äò", "*",  "=", "^", "‚ô´", "‚ö™", "‚îÄ", "‚ñ∫", "‚óã", "‚ÇÄ", "‚ÇÉ", "‚ÇÖ", "‚ÇÄ", "·¥¥·¥∞", "‚öô", "‚ùê", "‚äè", "‚äê", "‚Äö", "‚úì", "\\", "$", "¬£", "‚Ç¨", "+", "/", "=", "„ÄÉ", "·ê†", "ÔΩ°", "Íûà", "·êü‚Å†", "‰∫∫", "^",  "_", "-", "„ÄÉ"))
```


```{r}
#| label: join-stopwords
tokens_df <- anti_join(tokens_df, mystopwords, by="tokens")
```

The only punctuation I've kept is % because of its use in people "grading" games in their reviews. I wanted to keep + for similar reasons, but there were too many instances of it being used outside of relevant contexts that I decided losing it overall would be fine. 


```{r}
#| label: collapse-toks
merged_df <- tokens_df |>
  group_by(review_id) |>
  summarize(merged_text = paste(tokens, collapse = ", "))

nrow(merged_df)
```


```{r}
#| label: merged-reviews
reviews_df <- reviews_df |>
  left_join(merged_df)

reviews_df
```


I noticed that the merged df had a few less rows than the base reviews df does, and have to investigate why that is.


```{r}
#| label: findNA
colSums(is.na(reviews_df))
```

```{r}
#| label: browse-na
reviews_df |>
  filter(if_any(merged_text, is.na))
```

```{r}
#| label: remove-na
reviews_df <- reviews_df |>
  drop_na(merged_text)

nrow(reviews_df)
```

The removal of punctuation ended up cutting down on some rows. It saved us our emojis but removed some reviews that I saw at least that were just "???????", just an emoticon, or "....." etc. Some reviews had no text, it turns out, which became an N/A once tokenized, and those have been removed now as well. 


## One more thing...

When I got started on my analysis notebook, I found some additional cleaning up that I needed to do. This mostly was some odd unicode blank spaces that were affecting some of my looks at tokens and types, especially with emojis. I'm moving that here for the sake of cleanliness.

```{r}
#| label: toks-col
reviews_df <- reviews_df |>
  #rename from the tokenized col from before
  rename(tokens = merged_text)

reviews_df
```


```{r}
#| label: remove-unicode
#| include: FALSE
reviews_df <- reviews_df |>
  mutate(review = str_replace_all(review, "\\\u200B+|\\\u200E+|\\\u200C+|\\\UE0021+|\\\u00AD+|\\\u200F+|^\\\u3164+$|\\\u180C|^\\\u0020+$|\\\u2063|\\\u2060|\\\u0009|\\\u00A0|\\\u034F|\\\u1160|\\\u2000|\\\u2003|\\\u2004|\\\u200D|\\\u202A|\\\u202C|\\\u202F|\\\u2067|\\\u3000|\\\u3164|\\\uFE0E|\\\uFE0F|\\\uFEFF", " ")) |>
  mutate(tokens = str_replace_all(tokens, "\\\u200B+|\\\u200E+|\\\u200C+|\\\UE0021+|\\\u00AD+|\\\u200F+|^\\\u3164+$|\\\u180C|^\\\u0020+$|\\\u2063|\\\u2060|\\\u0009|\\\u00A0|\\\u034F|\\\u1160|\\\u2000|\\\u2003|\\\u2004|\\\u200D|\\\u202A|\\\u202C|\\\u202F|\\\u2067|\\\u3000|\\\u3164|\\\uFE0E|\\\uFE0F|\\\uFEFF", " ")) |>
  mutate(review = str_replace_all(review, "  +", " ")) |>
  mutate(tokens = str_replace_all(tokens, "  +", " ")) |>
  mutate(review = review |>
      na_if(" ")) |>
  drop_na('review')
```

  
## Write out reviews.csv


```{r}
#| label: reviews-csv
write_csv(reviews_df, file="../private/reviews_analyze.csv")
```




```{r}
#| label: sessioninfo
sessionInfo()
```

