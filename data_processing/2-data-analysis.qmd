---
title: "2-data-analysis"
format: gfm
---

```{r}
#| label: setup
#| include: false
library(tidyverse)
library(tidytext)
library(ggplot2)
```

**Note**: Please run [0-data-exploration](https://github.com/Data-Sci-2025/Steam-Reviews-Analysis/blob/main/data_processing/0-data-exploration.qmd) and [1-data-cleanup](https://github.com/Data-Sci-2025/Steam-Reviews-Analysis/blob/main/data_processing/1-data-cleanup.qmd) first to create the version of the .csv file needed to start here.



```{r}
#| label: readingin
reviews_df <- read_csv("../private/reviews_analyze.csv")
```


```{r}
#| label: toks-col
reviews_df <- reviews_df |>
  rename(tokens = merged_text)

reviews_df
```


Copied over from the last file in the pipeline to keep track.

## List of Goals

- adjust the date column (DONE)
- clean up the text of non text items (DONE)
- Word tokens and word count per review (DONE)
- word types (DONE)
- TTR (DONE)

**Early Exploration**

- average review length (DONE)
- most common words (with and without stop words)
- most common words for pos and for neg
- some stats (correlation) - length and review type, review and rating type, maybe some others
- TF-IDF
- maybe let's look at some emoji usage

**Later Goals**

- build a classifier 

## Some Missed Cleanup

While I was working on word counts I discovered a number of unicode blank spaces that were appearing as empty cells in the "review" column and were being counted as 1 word reviews. I had to go through, find the blank rows among the 1 word reviews, use charToRaw on the review ID associated, and search online to find the unicode string to search for and remove. 

I went over the top to remove from both reviews and token columns, just to be sure I was getting everything and removing the full row. It seemed like when I didn't, the rows weren't being entirely eliminated. Overkill is fine with me if the end result is what I'm after!

```{r}
reviews_df <- reviews_df |>
  mutate(review = str_replace_all(review, "\\\u200B+", " ")) |>
  mutate(tokens = str_replace_all(tokens, "\\\u200B+", " ")) |>
  mutate(review = str_replace_all(review, "\\\u200E+", " ")) |>
  mutate(tokens = str_replace_all(tokens, "\\\u200E+", " ")) |>
  mutate(review = str_replace_all(review, "\\\u200C+", " ")) |>
  mutate(tokens = str_replace_all(tokens, "\\\u200C+", " ")) |>
  mutate(review = str_replace_all(review, "\\\UE0021+", " ")) |>
  mutate(tokens = str_replace_all(tokens, "\\\UE0021+", " ")) |>
  mutate(review = str_replace_all(review, "\\\u00AD+", " ")) |>
  mutate(tokens = str_replace_all(tokens, "\\\u00AD+", " ")) |>
  mutate(review = str_replace_all(review, "\\\u200F+", " ")) |>
  mutate(tokens = str_replace_all(tokens, "\\\u200F+", " ")) |>
  mutate(review = str_replace_all(review, "^\\\u3164+$", " ")) |>
  mutate(tokens = str_replace_all(tokens, "^\\\u3164+$", " ")) |>
  mutate(review = str_replace_all(review, "\\\u180C", " ")) |>
  mutate(tokens = str_replace_all(tokens, "\\\u180C", " ")) |>
  mutate(review = str_replace_all(review, "^\\\u0020+$", " ")) |>
  mutate(tokens = str_replace_all(tokens, "^\\\u0020+$", " ")) |>
  mutate(review = str_replace_all(review, "\\\u2063", " ")) |>
  mutate(tokens = str_replace_all(tokens, "\\\u2063", " ")) |>
  mutate(review = str_replace_all(review, "\\\u2060", " ")) |>
  mutate(tokens = str_replace_all(tokens, "\\\u2060", " ")) |>
  mutate(review = review |>
      na_if(" ")) |>
  drop_na('review')
```


## Word Count

```{r}
#| label: word-count
reviews_df <- reviews_df |>
  mutate(word_count = str_count(tokens, '\\,')+1)

reviews_df
```

### Review length

First, there are a number of reviews that are just a blank space that were counted as having 1 word because of how I formulated the word count column. I'm going to declare these columns NA. If there's no text in the review, there's nothing there for me to analyze anyway. 


```{r}
summary(reviews_df$word_count)
```

So the average review is 51 words, and the median 17 words. 

Let's look a little deeper. 


```{r}
reviews_df |>
  filter(word_count==1)

reviews_df |>
  filter(word_count>1700)
```

There's quite a few one-word reviews! Some of them are pretty reasonable... "Amazing", "Spooky", "Boring", "Unplayable". Short and sweet, gets the point across well enough. Others are a little less obvious. I saw a number of keyboard smash reviews, strings of numbers, I saw one that was just a rabbit emoji. The last one might be a reference I just don't understand.

Looking instead at these longest reviews, I was really surprised! A huge majority of these are exactly the same phrase repeated over and over, and those repeated reviews are all for the same game, as well. I have to do some investigation... 

Checking my game info [here](https://github.com/Data-Sci-2025/Steam-Reviews-Analysis/blob/main/notes_and_info/0-gameinfo.csv), I was able to confirm that these repeating reviews are all from "The Stanley Parable: Ultra Deluxe". 

Looking further, I found some more information. ["The end is never"](https://thestanleyparable.fandom.com/wiki/The_End_Is_Never...) is a tagline for the game itself, and appears within the game multiple times as a reference to the inescapable time loop the game's protagonist is stuck in. The phrase also apparently appears on the game's loading screens in a constant loop. 


### Positive and Negative review length

First let's get a look at what we're working with. How many reviews of each type are there?

```{r}
ggplot(reviews_df, aes(x=review_type, fill=review_type )) + 
  geom_bar( width = 0.5) +
  scale_fill_brewer(palette = "Set2") +
  geom_text(stat = "count", aes(label = after_stat(count)), size = 3.5, vjust = 3, hjust = 0.5, position = "stack") +
  theme(legend.position="right")
```

There are a LOT more positive reviews than negative ones. This made me curious, what about the total data. It's possible positively reviewed games have more reviews in general than neagtively reviewed games? 

```{r}
games <- read_csv("../notes_and_info/0-gameinfo.csv")

games |>
  group_by(rank) |>
  #merging all varieties of pos/neg together by removing the first word/rank
  mutate(rank = str_replace_all(rank, "\\w+ (\\w)", "\\1")) |>
  summarise(eng_reviews = sum(eng_reviews))
```

It looks like kind of yes! 

My theory here just comes down to popularity. As a game releases and players try it out and review it, it either begins to migrate through the ranks of positive or negative. As new players find out about the game, if it shows already that it's being negatively reviewed, why would they spend money to try it out themselves? I wouldn't! On the other hand, if players see that a game is getting positive reviews, they'll more likely try it and, in turn, also positively review it.

Some of the games in the higher ranks in this data are hugely beloved games, while the negative ones are very likely largely forgotten to time once they descended into the negative review rankings. 

So, there it is. Positively ranked games have overall more reviews than negatively ranked games, and there are more positive reviews than negative ones in my data as a result. We'll keep that in mind, moving forward.


### Average Review Length

Now to what we came here to look into. Are positive reviews typically longer, or negative reviews? 


```{r}
ggplot(reviews_df, aes(x=review_type, y = word_count)) + 
  stat_summary(fun = mean, geom = "bar", fill = "skyblue") +
  geom_text(aes(label = after_stat(sprintf("%.2f", y))), stat = "summary", fun = "mean", vjust = 3, hjust=0.5) +
  ylab("Avg Amount") +
  theme(legend.position="right")
```

Now that's really interesting to me! Despite having fewer reviews total, and *all* of the longest reviews we looked at above being positive, negative reviews are still quite a bit longer on average. People must have a lot more to say when they dislike a game than when they like one!

I wonder if there's a trend in shorter reviews that might be swinging this average one way or the other. 

```{r}
reviews_df |>
  group_by(review_type) |>
  filter(word_count<6) |>
  summarise(word_count = sum(word_count))
```

Looks like it's pretty common for positive reviews to be shorter. this could potentially drag down the overall average of positive reviews.


## Word Types & Count

```{r}
#| label: GetTypes
remove_dupes <- function(x) {
  #split tokens to be iterated over
  words <- strsplit(x, " ")[[1]]
  #apply the unique() function per row
  unique_words <- unique(words)
  #re-collapse into rows
  paste(unique_words, collapse = " ")
}
```


```{r}
#| label: types-col
reviews_df$types <- sapply(reviews_df$tokens, remove_dupes)
```

```{r}
#| label: types-count
reviews_df <- reviews_df |>
  mutate(type_count = str_count(types, '\\,')+1)
```


## TTR 

TTR is used to measure the variety of language used in a text. It's not  exactly a measure of the complexity of a document, but can be considered with other factors as an indicator of a writer's language abilities. 

TTR is measured by dividing the total number of word types (unique words used) by total number of word tokens (all words used). A low score (closer to 0) indicates a highly repetitive document, and a high score (closer to 1) indicates a higher variety or words. A score of 1 would mean that no words were repeated in the document. 

TTR is very sensitive to document length. Too long, and documents taper off. There are only so many content words to be used in a document, eventually the highly repetitive function words will outnumber them. 

[source](https://medium.com/@rajeswaridepala/empirical-laws-ttr-cc9f826d304d)

```{r}
reviews_df <- reviews_df |>
  mutate(TTR = type_count/word_count)

reviews_df
```

Here I'll look at the range of TTR and see what I see. 






