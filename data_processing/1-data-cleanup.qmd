---
title: "analysis pipeline"
format: gfm
---

```{r}
#| label: setup
#| include: false
library(tidyverse)
```

**Note**: reviews.csv is too large to upload to github right now, but using the data which is uploaded and the "data exploration" file, if you un-comment the write_csv chunk, you should be able to recreate it just fine. You'll just have to change the file path to read in for this one. 


```{r}
#| label: readingin
reviews_df <- read_csv("../private/reviews.csv")
reviews_df
```

```{r}
#| label: game-ids
reviews_df |>
  distinct(steam_id)
```


## Cleaning Up


```{r}
#| label: posneg
reviews_df <- reviews_df |>
    mutate(review_type =  str_replace_all(review_type, 
                c("‚úÖ" = "POS",
                  "‚ùå" = "NEG")))
```


Fix those pesky emoji columns (I'm going to ditch the "purchased" column later on, so I didn't bother)

```{r}
#| label: reviews-df
reviews_df
```


```{r}
#| label: colchecks
diffrows <- reviews_df[reviews_df$review != reviews_df$engtxt, ]
diffrows
```

The engtxt column is not actually different from the review column, (it seems to auto translate the only difference being conversions of any reviews that just say "xx%" (100% being converted to 1) or anything with x/10 being also converted to a string of numbers. Since it's essentially the same data, I'll ditch the engtxt column and keep the review one.

Now for column decisions. I'll keep review_id since it's a unique value for each different review. 

I don't know that the date column is extremely important. I might want to look at how quickly games get reviews (are they concentrated at release and fall off, or is it relatively steady? any spikes?) but I will probably edit the column to a better format. Ditch the time, look into whatever format works best in R. 

I don't think the purchased col is extremely important, it only marks if a review writer has purchased the game or not, which is not key to any of my analysis.

score and upvotes are based on user response to a comment. Users can upvote for helpfulness of a review, or mark it as funny. I can't find data on how exactly the review score is calculated, but I don't think these two factors will play a huge role in what I'm looking to do. 


```{r}
#| label: reviews-df2
#narrowing the df down to only the columns I want
reviews_df <- reviews_df |>
  select(review_id:review_type, review, steam_id)
reviews_df
```

Now, I wanted to verify everything is correct. If every review ID is unique and I didn't accidentally duplicate anything, then piping the review_id column into distinct() should be the exact same dimensions as the full dataframe.

I had to run some fixes, but it's all good now!


```{r}
#| label: rowscheck
reviews_df |>
  distinct(review_id)
```


## List of Goals

- adjust the date column (DONE)
- clean up the text of non text items (IN PROGRESS)
- Word tokens and word count per review
- word types
- TTR

**Early Exploration**

- average review length
- most common words (with and without stop words)
- most common words for pos and for neg
- some stats (correlation) - length and review type, review and rating type, maybe some others
- TF-IDF

**Later Goals**

- build a classifier

## Date column

Date format as is: 2025.08.29 02:05

  - remove timestamp
  - reformat
  - change column class

```{r}
#| label: datecol
reviews_df <- reviews_df |>
  mutate(date = str_replace_all(date, "(\\d{4})\\.(\\d{2})\\.(\\d{2}).*", "\\1-\\2-\\3"))
reviews_df$date <- as.Date(reviews_df$date)  
  
reviews_df
```


## Text Cleaning

```{r}
#| label: review-text
reviews_df |>
  select(review)
```


```{r}
#| label: text-replace
reviews_df <- reviews_df |>
   mutate(review =  str_replace_all(review, 
                c("\n" = " ",
                  "\\(" = "",
                  "\\)" = "",
                  "(\\w)/(\\w)" = "\\1 \\2",
                  "(\\w) / (\\w)" = "\\1 \\2",
                  "\\[.*?\\]" = "",
                  "‚†∏|‚¢π|‚†£|‚£õ|‚££|‚£Å|‚£ñ|‚£≠|‚†É|‚¢ª|‚£ß|‚£Ω" = "",
                  "‚£∑|‚£ü|‚¢∂|‚¢£|‚†Ñ|‚°ø|‚£Æ|‚£ª|‚£¶|‚¢õ|‚†ø|‚¢≠|‚†º|‚¢Ä" = "",
                  "‚°â|‚£∂|‚†ò|‚¢ø|‚°†|‚¢Ü|‚£≥|‚°µ|‚°Ö|‚†ô|‚£º|‚°Ñ|‚°ß|‚¢á" = "",
                  "‚£¥|‚£å|‚¢Ω|‚†ª|‚°õ|‚£§|‚°ù|‚£æ|‚†ö|‚£Ä|‚†è|‚°ª|‚¢ò|‚†é" = "",
                  "‚£ù|‚£∏|‚£∞|‚°Ü|‚£±|‚£°|‚¢ü|‚£Ø|‚°ü|‚¢†|‚†ë|‚†õ|‚¢∏|‚¢Ø" = "",
                  "‚¢é|‚£ï|‚°Æ|‚†ù|‚°æ|‚°Ø|‚†ï|‚°π|‚°Ç|‚¢à|‚†ü|‚†¢|‚£é" = "",
                  "‚°™|‚°±|‚¢î|‚°ë|‚¢ä|‚¢ä|‚††|‚†°|‚†à|‚°å|‚†™|‚£∫|‚°Ω" = "",
                  "‚£ó|‚¢â|‚¢Ñ|‚£ê|‚¢Ç|‚¢ê|‚°î|‚°Ä|‚†Å|‚¢ë|‚¢®|‚°Å" = "",
                  "‚¢Æ|‚£Ü|‚†ê|‚£´|‚¢∑|‚¢Æ|‚¢ó|‚¢™|‚£¨|‚¢ú|‚¢æ|‚£û" = "",
                  "‚¢ó|‚†•|‚†®|‚¢™|‚†Ç|‚£¨|‚°ó|‚†ß|‚¢û|‚£™|‚¢±|‚£¨" = "",
                  "‚°®|‚°∑|‚¢ö|‚†π|‚°é|‚¢•|‚†Ä|‚°∫|‚¢å|‚°ä|‚°°|‚†±|‚†å" = "",
                  "‚°≤|‚£π|‚£ë|‚£®|‚¢≥|‚¢°|‚£ú|‚¢µ|‚£î|‚°∏|‚°≠|‚¢É" = "",
                  "‚¢¥|‚¢ï|‚°á|‚¢¨|‚¢Ö|‚£µ|‚†Æ|‚¢è|‚°í|‚°´|‚°ê|‚°≥" = "",
                  "‚†Ø|‚¢¢|‚°©|‚£É|‚†î|‚†ú|‚†á|‚†Ö|‚£á|‚°∞|‚†∞|‚£Ö" = "",
                  "‚°ò|‚°É|‚¢∞|‚°¨|‚°ú|‚¢ù|‚¢©|‚°¢|‚°º|‚£ò|‚†¨|‚†ä|‚¢§" = "",
                  "‚†´|‚¢º|‚°ï|‚£≤|‚°è|‚¢∫|‚°à|‚†§|‚£•|‚°•|‚†∂|‚†Ω|‚£•|‚¢¶" = "",
                  "‚†©|‚°ç|‚†µ|‚£â|‚£ö|‚†¥|‚†≠|‚£ì|‚°ã|‚†ó|‚£Ñ|‚£à|‚†ç" = "",
                  "‚†∫|‚£¢|‚†∑|‚†ã|‚†æ|‚£†|‚°¥|‚†Ü|‚¢ñ|‚†û|‚¢≤|‚¢Å|‚†â|‚¢ã" = "",
                  "‚¢ß|‚£Ç|‚¢ô|‚†≥|‚£è|‚°£|‚°û|‚†í|‚°∂|‚£©|‚†ì|‚£ç|‚†≤|‚°§" = "",
                  "‚¢´|‚£ô|‚£ä|‚†ñ|‚†¶|‚°ô|‚¢ì|‚°¶|‚£í|‚¢í|‚¢ç|‚¢í|‚£ã|‚£ã|‚°ñ|‚£ø|‚°ö|‚°ì" = "",
                  "‚ñÑ|‚ñë|‚îå|‚îº|‚ñê|‚ñÄ|‚ñì|‚ïù|‚ïî|‚ñå|‚ïó|‚ïö|‚ïê|‚ïë|‚ñí|√ë|‚îÇ|‚à©|‚ïì|‚ï´" = "",
                  "‚ïô|‚ï°|‚ï†|‚äô|‚ñÖ|‚î§|‚óè|‚ñÇ|‚ñÉ|‚ó•|‚ñà" = "",
                  
                  

                  "‚îÄ‚îÄ+" = "‚îÄ",
                  "__+" = "_",
                  
                  "  +" = " "
                  
                  )
                
                
                ))
```


I'm doing some exploring using str_view to dive in and look at what I want to get rid of to begin some real analysis. 

First - do I want to lowercase before tokenizing? I think yes but I have to recheck old homeworks to be sure. Definitely want to lowercase before looking at types and before doing tf-idf.

  - how do you make a set of word types in R anyway i don't know
  - probably by using unique() doy
  
Second - what to do with punctuation? I have to review previous work also.
  
For the sake of processing text, I'm first removing any parenthesis included. it could be interesting what gets put in a parenthetical statement vs outside, but for pure analysis and vectorizing we don't want them. 

There are some included kind of html(?) tags like [b] and [/b] of [h1] etc. I want to get rid of those too. 

Getting rid of /, sometimes it appears as word/word and others word / word. Replacing it with a space and will later process to move extra spaces down to one space
  - sometimes it appears in 7/10 or something. I'm keeping those but I have to think about what to do with it. It also depends on how the tokenizer handles it. If it tokenizes to [7] [/] [10] I think that's acceptable.

```{r}
grep -c -P


```



Questions - what do to with emojis? 

Sometimes they are used stylistically to split up reviews:
üìö Story / Narrative, ‚åõ Length, üîÅ Replayability

Other times functionally (this is about difficulty):
üî≤ Too easy
‚òëÔ∏è Casual-friendly
üî≤ Balanced/Normal
üî≤ Challenging
üî≤ Brutal but fair
üî≤ Pure chaos (PvP focus)

Sometimes in place of words:
At least one review, start to finish, contains one item only üí©
Another one looks like: This game is üí© but i still love it

Some reviews also have no words and will just say "7/10" and nothing else, what about those? 

What about abbreviations? I've seen af, wtf, omg, lmao, etc etc. 
  - there are a lot, i imagine just leave them as they are

There are also emoticons in the old style: :D, xD etc
I even saw ¬∞ Õú ñ Õ°¬∞, Ôæâ‚óï„ÉÆ‚óïÔæâ*:ÔΩ•Ôæü‚úß

LOTS of formatting choices people make for visual purposes:
=====, ‚òë and ‚òê (not as emojis), 

Or what about this...
There are a number of reviews using ‚£ø (and all the variations in the replace text chunk above) to create a kind of ASCII art that can be safely removed, it is not speech information at all.

Think about \\{.*?\\} - there are some unicodes that show up I was having trouble singling out so I have to figure that out. I think they're probably special characters used in some more elaborate emoticons/faces that didn't quite translate somewhere along the way. 

links? Lots of people are linking to things in their reviews.


```{r}
#| label: text-search
str_view(reviews_df$review, "/")
```


## Tokenizing

Testing out the tokenizing here to see if there's anything I need to change in the text cleanup chunk above before I move onto an analysis qmd

unnest tokens
you can mess with formatting if needed to select how you want things to tokenize

